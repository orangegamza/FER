{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "word2VecModel = KeyedVectors.load_word2vec_format('D:/gn/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "angry = word2VecModel['angry']\n",
    "disgust = word2VecModel['disgust']\n",
    "fear = word2VecModel['fear']\n",
    "happy = word2VecModel['happy']\n",
    "neutral = word2VecModel['neutral']\n",
    "sad = word2VecModel['sad']\n",
    "surprise = word2VecModel['surprise']\n",
    "\n",
    "weight = [angry, disgust, fear, happy, neutral, sad, surprise]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "print(tensorflow.test.is_built_with_cuda())\n",
    "print(tensorflow.test.is_built_with_gpu_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten,Dense,Dropout,BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, InceptionResNetV2\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop,SGD,Adamax\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "tsne = TSNE()\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "print(\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ax = sns.scatterplot(data=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"images/train\" #passing the path with training images\n",
    "test_dir = \"images/validation\"   #passing the path with testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 48 #original size of the image\n",
    "_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data Augmentation\n",
    "--------------------------\n",
    "rotation_range = rotates the image with the amount of degrees we provide\n",
    "width_shift_range = shifts the image randomly to the right or left along the width of the image\n",
    "height_shift range = shifts image randomly to up or below along the height of the image\n",
    "horizontal_flip = flips the image horizontally\n",
    "rescale = to scale down the pizel values in our image between 0 and 1\n",
    "zoom_range = applies random zoom to our object\n",
    "validation_split = reserves some images to be used for validation purpose\n",
    "\"\"\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(horizontal_flip = True,\n",
    "                                validation_split = 0.1,)\n",
    "validation_datagen = ImageDataGenerator(validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1260 images belonging to 7 classes.\n",
      "Found 140 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Applying data augmentation to the images as we read \n",
    "them from their respective directories\n",
    "\"\"\"\n",
    "train_generator = train_datagen.flow_from_directory(directory = train_dir,\n",
    "                                                    target_size = (img_size,img_size),\n",
    "                                                    class_mode = \"categorical\",\n",
    "                                                    color_mode = \"grayscale\",\n",
    "                                                    subset = \"training\",\n",
    "                                                    batch_size=_batch_size,\n",
    "                                                    shuffle=True\n",
    "                                                   )\n",
    "validation_generator = validation_datagen.flow_from_directory( directory = test_dir,\n",
    "                                                              target_size = (img_size,img_size),\n",
    "                                                              class_mode = \"categorical\",\n",
    "                                                              color_mode = \"grayscale\",\n",
    "                                                              subset = \"validation\",\n",
    "                                                              batch_size=_batch_size\n",
    "                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        x, y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)  # Forward pass\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            w = -100\n",
    "            for n in range(len(weight) - 1) : \n",
    "                a = cosine_similarity(a, y_pred)\n",
    "                if w < a :\n",
    "                    w = a\n",
    "                    y_pred = n\n",
    "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cosine_loss = tf.keras.losses.CosineSimilarity(axis=1)\n",
    "\n",
    "class NumLoss(tf.keras.losses.Loss) :\n",
    "    def call(self, y_true, y_pred):\n",
    "        difference = 0.\n",
    "        for n in range(len(y_true.numpy().tolist())-1) : \n",
    "            y_true_n = y_true.numpy().tolist()[n]\n",
    "            y_pred_n = y_pred.numpy().tolist()[n]\n",
    "            difference += abs(weight[int(y_true_n[0])] - y_pred_n)\n",
    "        m = tf.reduce_mean(difference / _batch_size) \n",
    "        print(m)\n",
    "        return m\n",
    "\n",
    "class WeightLayer(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(WeightLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=(input_shape[1], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(WeightLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        return keras.backend.dot(x, self.kernel)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "m_input = keras.Input(shape=(img_size, img_size, 1))\n",
    "x = keras.layers.Conv2D(32, (3,3), padding='same', activation='relu')(m_input)\n",
    "\n",
    "x = keras.layers.Conv2D(64, (3,3), padding='same', activation='relu')(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=(2,2))(x)\n",
    "x = keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "x = keras.layers.Conv2D(128, (3,3), padding='same', activation='relu')(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=(2,2))(x)\n",
    "x = keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "x = keras.layers.Conv2D(512, (3,3), padding='same', activation='relu')(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=(2,2))(x)\n",
    "x = keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "x = keras.layers.Conv2D(512, (3,3), padding='same', activation='relu')(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=(2,2))(x)\n",
    "x = keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "x = keras.layers.Flatten()(x)\n",
    "m_output = keras.layers.Dense(300, activation='relu')\n",
    "\n",
    "model = CustomModel(m_input, m_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= tf.keras.models.Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(48, 48,1)))\n",
    "model.add(Conv2D(64,(3,3), padding='same', activation='relu' ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128,(5,5), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "    \n",
    "model.add(Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(300, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model= tf.keras.models.Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(48, 48,1), kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(300, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {0:'Angry',1:'Disgust',2:'Fear',3:'Happy',4:'Neutral',5:'Sad',6:'Surprise'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cosine_loss = tf.keras.losses.CosineSimilarity()\n",
    "\n",
    "class NumLoss2(tf.keras.losses.Loss) :\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true_n = y_true.numpy().tolist()[0]\n",
    "        y_pred_n = y_pred.numpy().tolist()[0]\n",
    "        difference_n = abs(cosine_loss(weight[int(max(y_true_n))], y_pred_n).numpy())\n",
    "        for n in range(1, len(y_true.numpy().tolist())-2) : \n",
    "            y_true_n = y_true.numpy().tolist()[n]\n",
    "            y_pred_n = y_pred.numpy().tolist()[n]\n",
    "            difference = abs(cosine_loss(weight[int(max(y_true_n))], y_pred_n).numpy())\n",
    "            difference_n = difference + difference_n\n",
    "        m = difference_n / _batch_size\n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cosine_loss = tf.keras.losses.CosineSimilarity()\n",
    "\n",
    "class NumLoss(tf.keras.losses.Loss) :\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true_n = y_true.numpy().tolist()[0]\n",
    "        t = weight[y_true_n.index(int(max(y_true_n)))]\n",
    "        y_pred_n = y_pred.numpy().tolist()[0]\n",
    "        loss = tf.keras.losses.cosine_similarity(t, y_pred_n)\n",
    "        for i in range(1, len(y_true.numpy().tolist())-2) : \n",
    "            y_true_n = y_true.numpy().tolist()[i]\n",
    "            t = weight[y_true_n.index(int(max(y_true_n)))]\n",
    "            y_pred_n = y_pred.numpy().tolist()[i]\n",
    "            loss += tf.keras.losses.cosine_similarity(t, y_pred_n)\n",
    "        return tf.reduce_sum(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_accuracy():\n",
    "    def accuracy(y_true, y_pred):\n",
    "        score = 0\n",
    "        for n in range(len(y_true.numpy().tolist())-1) : \n",
    "            y_pred_n = [y_pred.numpy().tolist()[n][i] - 0.5 for i in range(len(y_pred.numpy().tolist()[n]))]\n",
    "            y_true_n = y_true.numpy().tolist()[n]\n",
    "            i = 0\n",
    "            w = 0.00\n",
    "            for m in range(len(weight)) : \n",
    "                a = abs(cosine_similarity(weight[m], y_pred_n))\n",
    "                if w < a : \n",
    "                    w = a\n",
    "                    i = m\n",
    "            if int(i) == int(y_true_n.index(int(max(y_true_n)))) :\n",
    "                score += 1\n",
    "            print(\"pred\", i, \"gt\", y_true_n.index(int(max(y_true_n))))\n",
    "        return score / _batch_size\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    run_eagerly = True,\n",
    "    optimizer = Adam(learning_rate=0.00001), \n",
    "    loss=NumLoss(),\n",
    "    metrics=[category_accuracy()]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 48, 48, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 48, 48, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 48, 48, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 24, 24, 128)       204928    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 12, 12, 512)       590336    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 12, 12, 512)      2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 6, 6, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 3, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               1382700   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,561,452\n",
      "Trainable params: 4,559,020\n",
      "Non-trainable params: 2,432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size=_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 2 gt 2\n",
      "pred 1 gt 5\n",
      "pred 2 gt 4\n",
      "pred 1 gt 4\n",
      "pred 1 gt 1\n",
      "pred 1 gt 4\n",
      "pred 4 gt 5\n",
      "pred 1 gt 3\n",
      "pred 1 gt 0\n",
      "pred 4 gt 3\n",
      "pred 2 gt 0\n",
      "pred 1 gt 6\n",
      "pred 1 gt 6\n",
      "pred 4 gt 2\n",
      "pred 2 gt 0\n",
      "pred 4 gt 1\n",
      "pred 3 gt 2\n",
      "pred 1 gt 5\n",
      "pred 4 gt 3\n",
      "pred 1 gt 4\n",
      "pred 4 gt 2\n",
      "pred 1 gt 5\n",
      "pred 4 gt 6\n",
      "pred 1 gt 5\n",
      "pred 2 gt 2\n",
      "pred 4 gt 2\n",
      "pred 2 gt 2\n",
      "pred 3 gt 1\n",
      "pred 1 gt 1\n",
      "pred 1 gt 3\n",
      "pred 1 gt 2\n",
      "pred 6 gt 1\n",
      "pred 0 gt 5\n",
      "pred 5 gt 4\n",
      "pred 2 gt 6\n",
      "pred 0 gt 2\n",
      "pred 0 gt 4\n",
      "pred 1 gt 1\n",
      "pred 0 gt 0\n",
      "pred 6 gt 4\n",
      "pred 2 gt 2\n",
      "pred 4 gt 6\n",
      "pred 4 gt 2\n",
      "pred 1 gt 5\n",
      "pred 4 gt 4\n",
      "pred 4 gt 0\n",
      "pred 1 gt 0\n",
      "pred 6 gt 4\n",
      "pred 2 gt 3\n",
      "pred 4 gt 1\n",
      "pred 1 gt 4\n",
      "pred 4 gt 6\n",
      "pred 1 gt 3\n",
      "pred 3 gt 5\n",
      "pred 3 gt 1\n",
      "pred 5 gt 4\n",
      "pred 3 gt 2\n",
      "pred 1 gt 6\n",
      "pred 0 gt 2\n",
      "pred 5 gt 6\n",
      "pred 0 gt 4\n",
      "pred 0 gt 6\n",
      "pred 3 gt 0\n",
      " 1/20 [>.............................] - ETA: 1:31 - loss: -0.8019 - accuracy: 0.1406WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 2 gt 0\n",
      "pred 3 gt 4\n",
      "pred 1 gt 2\n",
      "pred 2 gt 1\n",
      "pred 0 gt 0\n",
      "pred 5 gt 1\n",
      "pred 1 gt 5\n",
      "pred 5 gt 1\n",
      "pred 4 gt 6\n",
      "pred 4 gt 1\n",
      "pred 2 gt 3\n",
      "pred 1 gt 1\n",
      "pred 4 gt 5\n",
      "pred 1 gt 5\n",
      "pred 4 gt 6\n",
      "pred 1 gt 3\n",
      "pred 4 gt 1\n",
      "pred 0 gt 0\n",
      "pred 3 gt 2\n",
      "pred 2 gt 2\n",
      "pred 5 gt 0\n",
      "pred 6 gt 2\n",
      "pred 0 gt 2\n",
      "pred 1 gt 3\n",
      "pred 4 gt 4\n",
      "pred 6 gt 5\n",
      "pred 0 gt 4\n",
      "pred 4 gt 1\n",
      "pred 1 gt 1\n",
      "pred 6 gt 2\n",
      "pred 2 gt 4\n",
      "pred 2 gt 1\n",
      "pred 1 gt 3\n",
      "pred 3 gt 1\n",
      "pred 1 gt 6\n",
      "pred 5 gt 5\n",
      "pred 4 gt 6\n",
      "pred 1 gt 4\n",
      "pred 4 gt 1\n",
      "pred 1 gt 5\n",
      "pred 1 gt 6\n",
      "pred 2 gt 2\n",
      "pred 2 gt 1\n",
      "pred 4 gt 2\n",
      "pred 4 gt 2\n",
      "pred 6 gt 1\n",
      "pred 6 gt 3\n",
      "pred 4 gt 6\n",
      "pred 3 gt 4\n",
      "pred 4 gt 3\n",
      "pred 1 gt 0\n",
      "pred 4 gt 1\n",
      "pred 6 gt 6\n",
      "pred 2 gt 3\n",
      "pred 1 gt 3\n",
      "pred 2 gt 4\n",
      "pred 4 gt 4\n",
      "pred 1 gt 6\n",
      "pred 5 gt 3\n",
      "pred 2 gt 2\n",
      "pred 1 gt 5\n",
      "pred 2 gt 1\n",
      "pred 6 gt 4\n",
      " 2/20 [==>...........................] - ETA: 1:28 - loss: -1.1251 - accuracy: 0.1562WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 5 gt 2\n",
      "pred 1 gt 4\n",
      "pred 1 gt 6\n",
      "pred 6 gt 0\n",
      "pred 4 gt 1\n",
      "pred 3 gt 0\n",
      "pred 3 gt 1\n",
      "pred 6 gt 0\n",
      "pred 4 gt 1\n",
      "pred 4 gt 6\n",
      "pred 1 gt 3\n",
      "pred 3 gt 4\n",
      "pred 4 gt 1\n",
      "pred 2 gt 6\n",
      "pred 4 gt 5\n",
      "pred 6 gt 3\n",
      "pred 3 gt 4\n",
      "pred 1 gt 0\n",
      "pred 0 gt 0\n",
      "pred 0 gt 6\n",
      "pred 1 gt 6\n",
      "pred 4 gt 2\n",
      "pred 5 gt 1\n",
      "pred 1 gt 1\n",
      "pred 5 gt 2\n",
      "pred 5 gt 2\n",
      "pred 2 gt 2\n",
      "pred 1 gt 6\n",
      "pred 1 gt 3\n",
      "pred 1 gt 3\n",
      "pred 2 gt 4\n",
      "pred 4 gt 3\n",
      "pred 5 gt 2\n",
      "pred 4 gt 4\n",
      "pred 1 gt 0\n",
      "pred 2 gt 4\n",
      "pred 0 gt 6\n",
      "pred 3 gt 2\n",
      "pred 4 gt 6\n",
      "pred 1 gt 4\n",
      "pred 3 gt 3\n",
      "pred 3 gt 6\n",
      "pred 5 gt 2\n",
      "pred 1 gt 4\n",
      "pred 6 gt 4\n",
      "pred 4 gt 1\n",
      "pred 1 gt 3\n",
      "pred 1 gt 1\n",
      "pred 2 gt 4\n",
      "pred 2 gt 4\n",
      "pred 1 gt 1\n",
      "pred 4 gt 2\n",
      "pred 2 gt 6\n",
      "pred 2 gt 2\n",
      "pred 5 gt 2\n",
      "pred 4 gt 6\n",
      "pred 3 gt 6\n",
      "pred 2 gt 5\n",
      "pred 5 gt 2\n",
      "pred 2 gt 6\n",
      "pred 5 gt 0\n",
      "pred 1 gt 2\n",
      "pred 6 gt 2\n",
      " 3/20 [===>..........................] - ETA: 1:23 - loss: -0.8555 - accuracy: 0.1458WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 1 gt 1\n",
      "pred 0 gt 2\n",
      "pred 0 gt 0\n",
      "pred 3 gt 6\n",
      "pred 0 gt 4\n",
      "pred 0 gt 4\n",
      "pred 4 gt 2\n",
      "pred 4 gt 2\n",
      "pred 0 gt 3\n",
      "pred 6 gt 4\n",
      "pred 1 gt 0\n",
      "pred 4 gt 0\n",
      "pred 2 gt 4\n",
      "pred 4 gt 0\n",
      "pred 3 gt 6\n",
      "pred 1 gt 1\n",
      "pred 2 gt 0\n",
      "pred 1 gt 1\n",
      "pred 4 gt 3\n",
      "pred 4 gt 1\n",
      "pred 0 gt 3\n",
      "pred 1 gt 5\n",
      "pred 4 gt 3\n",
      "pred 4 gt 3\n",
      "pred 6 gt 6\n",
      "pred 5 gt 0\n",
      "pred 5 gt 2\n",
      "pred 1 gt 5\n",
      "pred 5 gt 6\n",
      "pred 3 gt 6\n",
      "pred 1 gt 6\n",
      "pred 0 gt 3\n",
      "pred 4 gt 4\n",
      "pred 2 gt 1\n",
      "pred 5 gt 2\n",
      "pred 3 gt 4\n",
      "pred 2 gt 1\n",
      "pred 1 gt 4\n",
      "pred 3 gt 1\n",
      "pred 4 gt 0\n",
      "pred 2 gt 6\n",
      "pred 2 gt 2\n",
      "pred 2 gt 3\n",
      "pred 5 gt 1\n",
      "pred 1 gt 1\n",
      "pred 6 gt 5\n",
      "pred 1 gt 3\n",
      "pred 2 gt 2\n",
      "pred 4 gt 1\n",
      "pred 0 gt 4\n",
      "pred 4 gt 0\n",
      "pred 2 gt 2\n",
      "pred 1 gt 5\n",
      "pred 0 gt 5\n",
      "pred 1 gt 1\n",
      "pred 0 gt 3\n",
      "pred 0 gt 4\n",
      "pred 1 gt 4\n",
      "pred 3 gt 0\n",
      "pred 6 gt 2\n",
      "pred 1 gt 1\n",
      "pred 0 gt 0\n",
      "pred 1 gt 6\n",
      " 4/20 [=====>........................] - ETA: 1:17 - loss: -0.9277 - accuracy: 0.1602WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 1 gt 5\n",
      "pred 2 gt 4\n",
      "pred 5 gt 0\n",
      "pred 1 gt 0\n",
      "pred 2 gt 1\n",
      "pred 2 gt 6\n",
      "pred 2 gt 0\n",
      "pred 0 gt 2\n",
      "pred 4 gt 1\n",
      "pred 3 gt 5\n",
      "pred 6 gt 5\n",
      "pred 5 gt 4\n",
      "pred 2 gt 2\n",
      "pred 4 gt 2\n",
      "pred 1 gt 1\n",
      "pred 2 gt 4\n",
      "pred 4 gt 3\n",
      "pred 1 gt 2\n",
      "pred 5 gt 1\n",
      "pred 1 gt 0\n",
      "pred 2 gt 0\n",
      "pred 4 gt 3\n",
      "pred 0 gt 3\n",
      "pred 2 gt 5\n",
      "pred 0 gt 3\n",
      "pred 0 gt 3\n",
      "pred 4 gt 2\n",
      "pred 5 gt 0\n",
      "pred 4 gt 5\n",
      "pred 5 gt 0\n",
      "pred 1 gt 3\n",
      "pred 2 gt 0\n",
      "pred 5 gt 1\n",
      "pred 4 gt 6\n",
      "pred 5 gt 4\n",
      "pred 4 gt 1\n",
      "pred 6 gt 2\n",
      "pred 4 gt 3\n",
      "pred 1 gt 2\n",
      "pred 0 gt 1\n",
      "pred 4 gt 5\n",
      "pred 0 gt 5\n",
      "pred 6 gt 6\n",
      "pred 2 gt 5\n",
      "pred 5 gt 0\n",
      "pred 5 gt 0\n",
      "pred 6 gt 3\n",
      "pred 4 gt 6\n",
      "pred 4 gt 1\n",
      "pred 2 gt 4\n",
      "pred 4 gt 3\n",
      "pred 2 gt 5\n",
      "pred 1 gt 5\n",
      "pred 2 gt 4\n",
      "pred 6 gt 5\n",
      "pred 4 gt 2\n",
      "pred 3 gt 6\n",
      "pred 1 gt 2\n",
      "pred 3 gt 5\n",
      "pred 6 gt 2\n",
      "pred 5 gt 0\n",
      "pred 4 gt 5\n",
      "pred 1 gt 4\n",
      " 5/20 [======>.......................] - ETA: 1:13 - loss: -1.0476 - accuracy: 0.1375WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 1 gt 5\n",
      "pred 3 gt 4\n",
      "pred 5 gt 0\n",
      "pred 3 gt 4\n",
      "pred 6 gt 3\n",
      "pred 4 gt 4\n",
      "pred 0 gt 2\n",
      "pred 1 gt 1\n",
      "pred 4 gt 2\n",
      "pred 1 gt 5\n",
      "pred 3 gt 5\n",
      "pred 3 gt 5\n",
      "pred 5 gt 5\n",
      "pred 2 gt 1\n",
      "pred 2 gt 5\n",
      "pred 1 gt 4\n",
      "pred 4 gt 6\n",
      "pred 1 gt 4\n",
      "pred 1 gt 6\n",
      "pred 4 gt 0\n",
      "pred 3 gt 6\n",
      "pred 0 gt 4\n",
      "pred 4 gt 1\n",
      "pred 1 gt 4\n",
      "pred 0 gt 3\n",
      "pred 1 gt 1\n",
      "pred 1 gt 5\n",
      "pred 1 gt 3\n",
      "pred 4 gt 3\n",
      "pred 0 gt 2\n",
      "pred 2 gt 1\n",
      "pred 5 gt 5\n",
      "pred 1 gt 4\n",
      "pred 2 gt 3\n",
      "pred 6 gt 1\n",
      "pred 4 gt 4\n",
      "pred 0 gt 2\n",
      "pred 1 gt 6\n",
      "pred 1 gt 6\n",
      "pred 2 gt 3\n",
      "pred 6 gt 0\n",
      "pred 2 gt 2\n",
      "pred 4 gt 5\n",
      "pred 4 gt 2\n",
      "pred 2 gt 2\n",
      "pred 3 gt 4\n",
      "pred 4 gt 3\n",
      "pred 1 gt 0\n",
      "pred 4 gt 0\n",
      "pred 4 gt 0\n",
      "pred 5 gt 3\n",
      "pred 1 gt 3\n",
      "pred 1 gt 1\n",
      "pred 5 gt 0\n",
      "pred 1 gt 1\n",
      "pred 4 gt 6\n",
      "pred 0 gt 1\n",
      "pred 5 gt 6\n",
      "pred 5 gt 4\n",
      "pred 4 gt 6\n",
      "pred 1 gt 1\n",
      "pred 6 gt 6\n",
      "pred 1 gt 2\n",
      " 6/20 [========>.....................] - ETA: 1:08 - loss: -1.1468 - accuracy: 0.1458WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 0 gt 5\n",
      "pred 4 gt 1\n",
      "pred 4 gt 0\n",
      "pred 4 gt 5\n",
      "pred 5 gt 0\n",
      "pred 3 gt 6\n",
      "pred 5 gt 0\n",
      "pred 4 gt 3\n",
      "pred 4 gt 2\n",
      "pred 6 gt 5\n",
      "pred 1 gt 0\n",
      "pred 2 gt 5\n",
      "pred 0 gt 5\n",
      "pred 4 gt 2\n",
      "pred 4 gt 3\n",
      "pred 4 gt 1\n",
      "pred 5 gt 0\n",
      "pred 1 gt 4\n",
      "pred 2 gt 5\n",
      "pred 4 gt 2\n",
      "pred 1 gt 4\n",
      "pred 2 gt 0\n",
      "pred 1 gt 6\n",
      "pred 2 gt 3\n",
      "pred 6 gt 5\n",
      "pred 0 gt 1\n",
      "pred 1 gt 5\n",
      "pred 1 gt 0\n",
      "pred 4 gt 4\n",
      "pred 4 gt 3\n",
      "pred 4 gt 0\n",
      "pred 5 gt 0\n",
      "pred 6 gt 3\n",
      "pred 4 gt 6\n",
      "pred 4 gt 1\n",
      "pred 0 gt 0\n",
      "pred 0 gt 3\n",
      "pred 6 gt 4\n",
      "pred 1 gt 0\n",
      "pred 1 gt 5\n",
      "pred 1 gt 0\n",
      "pred 3 gt 2\n",
      "pred 4 gt 6\n",
      "pred 1 gt 3\n",
      "pred 3 gt 6\n",
      "pred 2 gt 6\n",
      "pred 4 gt 1\n",
      "pred 1 gt 3\n",
      "pred 3 gt 6\n",
      "pred 5 gt 1\n",
      "pred 1 gt 5\n",
      "pred 5 gt 0\n",
      "pred 0 gt 5\n",
      "pred 3 gt 0\n",
      "pred 2 gt 1\n",
      "pred 4 gt 0\n",
      "pred 6 gt 5\n",
      "pred 4 gt 3\n",
      "pred 4 gt 0\n",
      "pred 3 gt 3\n",
      "pred 2 gt 1\n",
      "pred 6 gt 4\n",
      "pred 0 gt 6\n",
      " 7/20 [=========>....................] - ETA: 1:03 - loss: -1.2546 - accuracy: 0.1317WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 4 gt 4\n",
      "pred 4 gt 6\n",
      "pred 2 gt 3\n",
      "pred 2 gt 3\n",
      "pred 4 gt 6\n",
      "pred 5 gt 4\n",
      "pred 1 gt 5\n",
      "pred 2 gt 3\n",
      "pred 6 gt 6\n",
      "pred 5 gt 4\n",
      "pred 4 gt 3\n",
      "pred 0 gt 3\n",
      "pred 1 gt 1\n",
      "pred 4 gt 2\n",
      "pred 4 gt 3\n",
      "pred 1 gt 4\n",
      "pred 4 gt 3\n",
      "pred 1 gt 2\n",
      "pred 2 gt 1\n",
      "pred 1 gt 1\n",
      "pred 1 gt 2\n",
      "pred 1 gt 4\n",
      "pred 6 gt 6\n",
      "pred 0 gt 6\n",
      "pred 4 gt 5\n",
      "pred 1 gt 1\n",
      "pred 4 gt 5\n",
      "pred 2 gt 4\n",
      "pred 4 gt 3\n",
      "pred 4 gt 6\n",
      "pred 0 gt 3\n",
      "pred 0 gt 5\n",
      "pred 4 gt 4\n",
      "pred 0 gt 2\n",
      "pred 4 gt 3\n",
      "pred 1 gt 6\n",
      "pred 4 gt 4\n",
      "pred 4 gt 1\n",
      "pred 6 gt 1\n",
      "pred 4 gt 4\n",
      "pred 1 gt 6\n",
      "pred 2 gt 6\n",
      "pred 2 gt 2\n",
      "pred 3 gt 1\n",
      "pred 4 gt 3\n",
      "pred 1 gt 5\n",
      "pred 4 gt 1\n",
      "pred 0 gt 3\n",
      "pred 6 gt 0\n",
      "pred 0 gt 4\n",
      "pred 1 gt 2\n",
      "pred 3 gt 2\n",
      "pred 1 gt 0\n",
      "pred 5 gt 6\n",
      "pred 1 gt 5\n",
      "pred 4 gt 6\n",
      "pred 5 gt 6\n",
      "pred 3 gt 1\n",
      "pred 5 gt 6\n",
      "pred 1 gt 3\n",
      "pred 1 gt 1\n",
      "pred 2 gt 6\n",
      "pred 4 gt 3\n",
      " 8/20 [===========>..................] - ETA: 58s - loss: -1.3037 - accuracy: 0.1367 WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 0 gt 5\n",
      "pred 0 gt 6\n",
      "pred 1 gt 5\n",
      "pred 2 gt 2\n",
      "pred 4 gt 4\n",
      "pred 1 gt 1\n",
      "pred 4 gt 2\n",
      "pred 4 gt 1\n",
      "pred 3 gt 1\n",
      "pred 1 gt 3\n",
      "pred 1 gt 4\n",
      "pred 2 gt 1\n",
      "pred 1 gt 2\n",
      "pred 1 gt 4\n",
      "pred 1 gt 5\n",
      "pred 6 gt 1\n",
      "pred 4 gt 4\n",
      "pred 3 gt 1\n",
      "pred 1 gt 3\n",
      "pred 4 gt 4\n",
      "pred 1 gt 6\n",
      "pred 5 gt 3\n",
      "pred 4 gt 5\n",
      "pred 6 gt 0\n",
      "pred 4 gt 2\n",
      "pred 2 gt 4\n",
      "pred 0 gt 3\n",
      "pred 6 gt 5\n",
      "pred 2 gt 3\n",
      "pred 1 gt 5\n",
      "pred 0 gt 2\n",
      "pred 2 gt 1\n",
      "pred 1 gt 2\n",
      "pred 0 gt 3\n",
      "pred 1 gt 5\n",
      "pred 1 gt 1\n",
      "pred 1 gt 2\n",
      "pred 4 gt 1\n",
      "pred 4 gt 3\n",
      "pred 0 gt 2\n",
      "pred 1 gt 1\n",
      "pred 1 gt 5\n",
      "pred 4 gt 2\n",
      "pred 2 gt 6\n",
      "pred 4 gt 1\n",
      "pred 0 gt 0\n",
      "pred 1 gt 5\n",
      "pred 2 gt 0\n",
      "pred 4 gt 6\n",
      "pred 6 gt 4\n",
      "pred 2 gt 3\n",
      "pred 4 gt 3\n",
      "pred 1 gt 5\n",
      "pred 4 gt 1\n",
      "pred 3 gt 2\n",
      "pred 3 gt 3\n",
      "pred 0 gt 0\n",
      "pred 4 gt 1\n",
      "pred 6 gt 5\n",
      "pred 0 gt 6\n",
      "pred 1 gt 2\n",
      "pred 4 gt 3\n",
      "pred 3 gt 6\n",
      " 9/20 [============>.................] - ETA: 53s - loss: -1.3533 - accuracy: 0.1389WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 3 gt 4\n",
      "pred 4 gt 0\n",
      "pred 0 gt 6\n",
      "pred 4 gt 6\n",
      "pred 1 gt 2\n",
      "pred 1 gt 3\n",
      "pred 3 gt 4\n",
      "pred 6 gt 0\n",
      "pred 1 gt 2\n",
      "pred 1 gt 4\n",
      "pred 4 gt 3\n",
      "pred 3 gt 1\n",
      "pred 5 gt 6\n",
      "pred 0 gt 4\n",
      "pred 6 gt 1\n",
      "pred 4 gt 0\n",
      "pred 1 gt 2\n",
      "pred 4 gt 6\n",
      "pred 4 gt 6\n",
      "pred 1 gt 0\n",
      "pred 4 gt 5\n",
      "pred 4 gt 6\n",
      "pred 6 gt 1\n",
      "pred 1 gt 5\n",
      "pred 2 gt 0\n",
      "pred 0 gt 2\n",
      "pred 4 gt 3\n",
      "pred 3 gt 6\n",
      "pred 1 gt 1\n",
      "pred 0 gt 2\n",
      "pred 1 gt 2\n",
      "pred 1 gt 6\n",
      "pred 3 gt 3\n",
      "pred 6 gt 0\n",
      "pred 1 gt 3\n",
      "pred 0 gt 4\n",
      "pred 1 gt 5\n",
      "pred 0 gt 2\n",
      "pred 4 gt 2\n",
      "pred 2 gt 0\n",
      "pred 5 gt 0\n",
      "pred 1 gt 3\n",
      "pred 4 gt 6\n",
      "pred 4 gt 1\n",
      "pred 2 gt 2\n",
      "pred 4 gt 0\n",
      "pred 0 gt 0\n",
      "pred 1 gt 1\n",
      "pred 5 gt 1\n",
      "pred 3 gt 3\n",
      "pred 6 gt 5\n",
      "pred 1 gt 2\n",
      "pred 1 gt 6\n",
      "pred 2 gt 3\n",
      "pred 3 gt 1\n",
      "pred 1 gt 0\n",
      "pred 4 gt 3\n",
      "pred 4 gt 6\n",
      "pred 2 gt 2\n",
      "pred 4 gt 4\n",
      "pred 3 gt 4\n",
      "pred 4 gt 4\n",
      "pred 1 gt 5\n",
      "10/20 [==============>...............] - ETA: 49s - loss: -1.2808 - accuracy: 0.1391WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 1 gt 3\n",
      "pred 5 gt 5\n",
      "pred 1 gt 0\n",
      "pred 5 gt 5\n",
      "pred 1 gt 5\n",
      "pred 6 gt 2\n",
      "pred 2 gt 2\n",
      "pred 0 gt 1\n",
      "pred 5 gt 4\n",
      "pred 6 gt 0\n",
      "pred 6 gt 0\n",
      "pred 4 gt 3\n",
      "pred 0 gt 3\n",
      "pred 6 gt 1\n",
      "pred 1 gt 3\n",
      "pred 1 gt 0\n",
      "pred 0 gt 5\n",
      "pred 1 gt 2\n",
      "pred 2 gt 0\n",
      "pred 1 gt 1\n",
      "pred 6 gt 5\n",
      "pred 5 gt 2\n",
      "pred 4 gt 0\n",
      "pred 2 gt 6\n",
      "pred 0 gt 5\n",
      "pred 0 gt 2\n",
      "pred 4 gt 4\n",
      "pred 2 gt 0\n",
      "pred 4 gt 3\n",
      "pred 2 gt 0\n",
      "pred 4 gt 3\n",
      "pred 1 gt 2\n",
      "pred 0 gt 4\n",
      "pred 4 gt 0\n",
      "pred 0 gt 3\n",
      "pred 1 gt 5\n",
      "pred 4 gt 6\n",
      "pred 5 gt 1\n",
      "pred 2 gt 3\n",
      "pred 4 gt 4\n",
      "pred 4 gt 6\n",
      "pred 0 gt 5\n",
      "pred 3 gt 3\n",
      "pred 4 gt 6\n",
      "pred 1 gt 3\n",
      "pred 3 gt 1\n",
      "pred 4 gt 2\n",
      "pred 5 gt 2\n",
      "pred 5 gt 2\n",
      "pred 3 gt 0\n",
      "pred 1 gt 4\n",
      "pred 5 gt 6\n",
      "pred 4 gt 5\n",
      "pred 3 gt 0\n",
      "pred 6 gt 3\n",
      "pred 4 gt 2\n",
      "pred 0 gt 0\n",
      "pred 4 gt 4\n",
      "pred 2 gt 2\n",
      "pred 2 gt 6\n",
      "pred 4 gt 4\n",
      "pred 1 gt 5\n",
      "pred 1 gt 4\n",
      "11/20 [===============>..............] - ETA: 44s - loss: -1.2662 - accuracy: 0.1420WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 5 gt 5\n",
      "pred 1 gt 2\n",
      "pred 2 gt 4\n",
      "pred 5 gt 3\n",
      "pred 4 gt 0\n",
      "pred 1 gt 0\n",
      "pred 1 gt 0\n",
      "pred 4 gt 6\n",
      "pred 1 gt 5\n",
      "pred 0 gt 5\n",
      "pred 4 gt 5\n",
      "pred 3 gt 4\n",
      "pred 4 gt 3\n",
      "pred 4 gt 6\n",
      "pred 1 gt 5\n",
      "pred 1 gt 5\n",
      "pred 0 gt 1\n",
      "pred 1 gt 3\n",
      "pred 1 gt 3\n",
      "pred 1 gt 1\n",
      "pred 6 gt 5\n",
      "pred 1 gt 2\n",
      "pred 5 gt 5\n",
      "pred 4 gt 0\n",
      "pred 1 gt 2\n",
      "pred 0 gt 0\n",
      "pred 1 gt 0\n",
      "pred 3 gt 6\n",
      "pred 1 gt 2\n",
      "pred 4 gt 6\n",
      "pred 0 gt 0\n",
      "pred 4 gt 2\n",
      "pred 0 gt 5\n",
      "pred 4 gt 4\n",
      "pred 1 gt 4\n",
      "pred 1 gt 2\n",
      "pred 4 gt 5\n",
      "pred 3 gt 1\n",
      "pred 3 gt 1\n",
      "pred 4 gt 2\n",
      "pred 6 gt 6\n",
      "pred 5 gt 1\n",
      "pred 1 gt 2\n",
      "pred 1 gt 6\n",
      "pred 4 gt 6\n",
      "pred 1 gt 2\n",
      "pred 5 gt 6\n",
      "pred 4 gt 5\n",
      "pred 5 gt 0\n",
      "pred 1 gt 6\n",
      "pred 4 gt 3\n",
      "pred 2 gt 0\n",
      "pred 4 gt 2\n",
      "pred 0 gt 4\n",
      "pred 4 gt 2\n",
      "pred 2 gt 2\n",
      "pred 4 gt 2\n",
      "pred 0 gt 4\n",
      "pred 0 gt 1\n",
      "pred 4 gt 4\n",
      "pred 4 gt 6\n",
      "pred 4 gt 6\n",
      "pred 4 gt 1\n",
      "12/20 [=================>............] - ETA: 39s - loss: -1.2273 - accuracy: 0.1419WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 2 gt 2\n",
      "pred 3 gt 3\n",
      "pred 6 gt 5\n",
      "pred 2 gt 4\n",
      "pred 4 gt 0\n",
      "pred 4 gt 6\n",
      "pred 3 gt 4\n",
      "pred 1 gt 5\n",
      "pred 5 gt 6\n",
      "pred 4 gt 3\n",
      "pred 1 gt 6\n",
      "pred 6 gt 0\n",
      "pred 1 gt 1\n",
      "pred 4 gt 6\n",
      "pred 1 gt 6\n",
      "pred 5 gt 2\n",
      "pred 1 gt 1\n",
      "pred 1 gt 5\n",
      "pred 0 gt 4\n",
      "pred 3 gt 6\n",
      "pred 4 gt 1\n",
      "pred 1 gt 3\n",
      "pred 1 gt 0\n",
      "pred 1 gt 4\n",
      "pred 0 gt 5\n",
      "pred 2 gt 4\n",
      "pred 5 gt 0\n",
      "pred 0 gt 6\n",
      "pred 1 gt 3\n",
      "pred 5 gt 4\n",
      "pred 1 gt 6\n",
      "pred 1 gt 1\n",
      "pred 0 gt 0\n",
      "pred 0 gt 4\n",
      "pred 3 gt 4\n",
      "pred 0 gt 2\n",
      "pred 0 gt 3\n",
      "pred 4 gt 4\n",
      "pred 4 gt 4\n",
      "pred 0 gt 5\n",
      "pred 4 gt 5\n",
      "pred 0 gt 4\n",
      "pred 4 gt 1\n",
      "pred 4 gt 1\n",
      "pred 4 gt 2\n",
      "pred 4 gt 1\n",
      "pred 1 gt 2\n",
      "pred 6 gt 4\n",
      "pred 4 gt 5\n",
      "pred 1 gt 5\n",
      "pred 0 gt 0\n",
      "pred 4 gt 2\n",
      "pred 4 gt 6\n",
      "pred 2 gt 0\n",
      "pred 4 gt 5\n",
      "pred 2 gt 5\n",
      "pred 1 gt 3\n",
      "pred 1 gt 6\n",
      "pred 4 gt 1\n",
      "pred 2 gt 6\n",
      "pred 4 gt 0\n",
      "pred 5 gt 3\n",
      "pred 3 gt 5\n",
      "13/20 [==================>...........] - ETA: 34s - loss: -1.2561 - accuracy: 0.1418WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 0 gt 6\n",
      "pred 4 gt 1\n",
      "pred 1 gt 4\n",
      "pred 5 gt 3\n",
      "pred 3 gt 1\n",
      "pred 2 gt 5\n",
      "pred 0 gt 5\n",
      "pred 4 gt 2\n",
      "pred 2 gt 1\n",
      "pred 5 gt 0\n",
      "pred 3 gt 5\n",
      "pred 0 gt 6\n",
      "pred 4 gt 1\n",
      "pred 6 gt 3\n",
      "pred 4 gt 3\n",
      "pred 4 gt 5\n",
      "pred 5 gt 2\n",
      "pred 4 gt 6\n",
      "pred 1 gt 0\n",
      "pred 4 gt 4\n",
      "pred 1 gt 0\n",
      "pred 6 gt 4\n",
      "pred 1 gt 0\n",
      "pred 1 gt 6\n",
      "pred 2 gt 4\n",
      "pred 4 gt 6\n",
      "pred 1 gt 3\n",
      "pred 4 gt 4\n",
      "pred 1 gt 3\n",
      "pred 1 gt 1\n",
      "pred 4 gt 4\n",
      "pred 0 gt 5\n",
      "pred 5 gt 6\n",
      "pred 0 gt 3\n",
      "pred 1 gt 3\n",
      "pred 1 gt 6\n",
      "pred 4 gt 4\n",
      "pred 5 gt 1\n",
      "pred 1 gt 5\n",
      "pred 1 gt 4\n",
      "pred 1 gt 0\n",
      "pred 6 gt 2\n",
      "pred 1 gt 6\n",
      "pred 4 gt 0\n",
      "pred 3 gt 5\n",
      "pred 1 gt 4\n",
      "pred 6 gt 5\n",
      "pred 0 gt 0\n",
      "pred 1 gt 0\n",
      "pred 0 gt 4\n",
      "pred 2 gt 5\n",
      "pred 6 gt 4\n",
      "pred 1 gt 5\n",
      "pred 4 gt 5\n",
      "pred 5 gt 1\n",
      "pred 6 gt 4\n",
      "pred 4 gt 3\n",
      "pred 0 gt 5\n",
      "pred 1 gt 3\n",
      "pred 1 gt 4\n",
      "pred 5 gt 1\n",
      "pred 3 gt 1\n",
      "pred 3 gt 3\n",
      "14/20 [====================>.........] - ETA: 29s - loss: -1.3251 - accuracy: 0.1395WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 2 gt 6\n",
      "pred 1 gt 2\n",
      "pred 2 gt 1\n",
      "pred 5 gt 5\n",
      "pred 1 gt 1\n",
      "pred 4 gt 0\n",
      "pred 2 gt 1\n",
      "pred 5 gt 1\n",
      "pred 2 gt 0\n",
      "pred 2 gt 0\n",
      "pred 3 gt 1\n",
      "pred 3 gt 1\n",
      "pred 3 gt 0\n",
      "pred 6 gt 3\n",
      "pred 5 gt 3\n",
      "pred 1 gt 0\n",
      "pred 1 gt 0\n",
      "pred 1 gt 1\n",
      "pred 4 gt 0\n",
      "pred 3 gt 1\n",
      "pred 1 gt 5\n",
      "pred 3 gt 2\n",
      "pred 2 gt 2\n",
      "pred 1 gt 4\n",
      "pred 5 gt 5\n",
      "pred 0 gt 4\n",
      "pred 1 gt 3\n",
      "pred 4 gt 1\n",
      "pred 1 gt 2\n",
      "pred 2 gt 5\n",
      "pred 6 gt 4\n",
      "pred 4 gt 4\n",
      "pred 1 gt 0\n",
      "pred 3 gt 6\n",
      "pred 2 gt 6\n",
      "pred 0 gt 2\n",
      "pred 0 gt 2\n",
      "pred 4 gt 3\n",
      "pred 2 gt 1\n",
      "pred 3 gt 4\n",
      "pred 4 gt 4\n",
      "pred 0 gt 0\n",
      "pred 4 gt 4\n",
      "15/20 [=====================>........] - ETA: 23s - loss: -1.2993 - accuracy: 0.1396WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 2 gt 4\n",
      "pred 1 gt 3\n",
      "pred 2 gt 5\n",
      "pred 1 gt 5\n",
      "pred 0 gt 0\n",
      "pred 1 gt 1\n",
      "pred 4 gt 3\n",
      "pred 1 gt 1\n",
      "pred 4 gt 3\n",
      "pred 3 gt 4\n",
      "pred 1 gt 2\n",
      "pred 3 gt 6\n",
      "pred 4 gt 3\n",
      "pred 4 gt 0\n",
      "pred 4 gt 6\n",
      "pred 4 gt 5\n",
      "pred 3 gt 0\n",
      "pred 4 gt 6\n",
      "pred 2 gt 2\n",
      "pred 5 gt 5\n",
      "pred 1 gt 5\n",
      "pred 3 gt 3\n",
      "pred 5 gt 5\n",
      "pred 1 gt 5\n",
      "pred 1 gt 0\n",
      "pred 1 gt 4\n",
      "pred 1 gt 1\n",
      "pred 3 gt 3\n",
      "pred 1 gt 4\n",
      "pred 1 gt 6\n",
      "pred 1 gt 6\n",
      "pred 5 gt 4\n",
      "pred 3 gt 3\n",
      "pred 4 gt 5\n",
      "pred 4 gt 6\n",
      "pred 4 gt 0\n",
      "pred 4 gt 1\n",
      "pred 1 gt 4\n",
      "pred 4 gt 0\n",
      "pred 2 gt 4\n",
      "pred 3 gt 0\n",
      "pred 4 gt 5\n",
      "pred 4 gt 3\n",
      "pred 1 gt 5\n",
      "pred 4 gt 4\n",
      "pred 4 gt 4\n",
      "pred 1 gt 1\n",
      "pred 0 gt 1\n",
      "pred 5 gt 6\n",
      "pred 4 gt 5\n",
      "pred 4 gt 5\n",
      "pred 2 gt 0\n",
      "pred 3 gt 0\n",
      "pred 4 gt 4\n",
      "pred 1 gt 3\n",
      "pred 0 gt 1\n",
      "pred 4 gt 5\n",
      "pred 4 gt 4\n",
      "pred 1 gt 2\n",
      "pred 5 gt 2\n",
      "pred 0 gt 2\n",
      "pred 0 gt 4\n",
      "pred 0 gt 3\n",
      "16/20 [=======================>......] - ETA: 18s - loss: -1.3450 - accuracy: 0.1455WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 5 gt 5\n",
      "pred 3 gt 1\n",
      "pred 0 gt 4\n",
      "pred 0 gt 2\n",
      "pred 1 gt 0\n",
      "pred 3 gt 0\n",
      "pred 2 gt 3\n",
      "pred 2 gt 0\n",
      "pred 6 gt 2\n",
      "pred 4 gt 5\n",
      "pred 0 gt 3\n",
      "pred 5 gt 2\n",
      "pred 4 gt 0\n",
      "pred 1 gt 3\n",
      "pred 4 gt 2\n",
      "pred 5 gt 3\n",
      "pred 1 gt 0\n",
      "pred 6 gt 2\n",
      "pred 5 gt 5\n",
      "pred 1 gt 4\n",
      "pred 1 gt 2\n",
      "pred 6 gt 5\n",
      "pred 5 gt 4\n",
      "pred 2 gt 5\n",
      "pred 4 gt 0\n",
      "pred 1 gt 2\n",
      "pred 3 gt 5\n",
      "pred 4 gt 0\n",
      "pred 2 gt 1\n",
      "pred 2 gt 2\n",
      "pred 0 gt 3\n",
      "pred 4 gt 1\n",
      "pred 2 gt 1\n",
      "pred 4 gt 2\n",
      "pred 4 gt 6\n",
      "pred 2 gt 2\n",
      "pred 1 gt 3\n",
      "pred 4 gt 2\n",
      "pred 2 gt 6\n",
      "pred 2 gt 6\n",
      "pred 6 gt 2\n",
      "pred 3 gt 1\n",
      "pred 4 gt 0\n",
      "pred 1 gt 3\n",
      "pred 1 gt 6\n",
      "pred 4 gt 6\n",
      "pred 2 gt 5\n",
      "pred 0 gt 1\n",
      "pred 1 gt 0\n",
      "pred 2 gt 4\n",
      "pred 3 gt 4\n",
      "pred 1 gt 2\n",
      "pred 4 gt 4\n",
      "pred 4 gt 3\n",
      "pred 4 gt 4\n",
      "pred 4 gt 0\n",
      "pred 4 gt 3\n",
      "pred 5 gt 1\n",
      "pred 1 gt 1\n",
      "pred 1 gt 3\n",
      "pred 4 gt 4\n",
      "pred 4 gt 2\n",
      "pred 3 gt 4\n",
      "17/20 [========================>.....] - ETA: 14s - loss: -1.3083 - accuracy: 0.1443WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 0 gt 6\n",
      "pred 4 gt 0\n",
      "pred 1 gt 5\n",
      "pred 1 gt 6\n",
      "pred 5 gt 3\n",
      "pred 1 gt 5\n",
      "pred 3 gt 6\n",
      "pred 1 gt 2\n",
      "pred 1 gt 1\n",
      "pred 4 gt 0\n",
      "pred 0 gt 5\n",
      "pred 1 gt 3\n",
      "pred 1 gt 2\n",
      "pred 4 gt 4\n",
      "pred 5 gt 3\n",
      "pred 0 gt 6\n",
      "pred 4 gt 2\n",
      "pred 6 gt 3\n",
      "pred 4 gt 3\n",
      "pred 2 gt 5\n",
      "pred 1 gt 0\n",
      "pred 4 gt 2\n",
      "pred 4 gt 0\n",
      "pred 4 gt 6\n",
      "pred 5 gt 1\n",
      "pred 0 gt 2\n",
      "pred 0 gt 2\n",
      "pred 1 gt 1\n",
      "pred 0 gt 0\n",
      "pred 1 gt 3\n",
      "pred 1 gt 5\n",
      "pred 3 gt 4\n",
      "pred 3 gt 0\n",
      "pred 5 gt 2\n",
      "pred 1 gt 5\n",
      "pred 2 gt 6\n",
      "pred 0 gt 4\n",
      "pred 4 gt 3\n",
      "pred 4 gt 2\n",
      "pred 1 gt 0\n",
      "pred 1 gt 2\n",
      "pred 4 gt 4\n",
      "pred 4 gt 2\n",
      "pred 2 gt 6\n",
      "pred 1 gt 0\n",
      "pred 4 gt 6\n",
      "pred 5 gt 3\n",
      "pred 4 gt 4\n",
      "pred 1 gt 1\n",
      "pred 2 gt 0\n",
      "pred 1 gt 5\n",
      "pred 4 gt 6\n",
      "pred 1 gt 6\n",
      "pred 1 gt 0\n",
      "pred 2 gt 6\n",
      "pred 6 gt 2\n",
      "pred 2 gt 4\n",
      "pred 4 gt 0\n",
      "pred 0 gt 1\n",
      "pred 3 gt 2\n",
      "pred 4 gt 1\n",
      "pred 0 gt 3\n",
      "pred 4 gt 3\n",
      "18/20 [==========================>...] - ETA: 9s - loss: -1.2733 - accuracy: 0.1424 WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 0 gt 1\n",
      "pred 0 gt 4\n",
      "pred 2 gt 3\n",
      "pred 1 gt 2\n",
      "pred 1 gt 0\n",
      "pred 0 gt 3\n",
      "pred 4 gt 4\n",
      "pred 1 gt 6\n",
      "pred 1 gt 6\n",
      "pred 5 gt 2\n",
      "pred 4 gt 5\n",
      "pred 4 gt 4\n",
      "pred 0 gt 1\n",
      "pred 4 gt 3\n",
      "pred 0 gt 0\n",
      "pred 5 gt 3\n",
      "pred 3 gt 4\n",
      "pred 4 gt 1\n",
      "pred 2 gt 3\n",
      "pred 4 gt 0\n",
      "pred 4 gt 2\n",
      "pred 1 gt 3\n",
      "pred 1 gt 3\n",
      "pred 5 gt 6\n",
      "pred 0 gt 1\n",
      "pred 0 gt 1\n",
      "pred 0 gt 5\n",
      "pred 6 gt 0\n",
      "pred 2 gt 5\n",
      "pred 1 gt 1\n",
      "pred 1 gt 4\n",
      "pred 6 gt 2\n",
      "pred 1 gt 0\n",
      "pred 4 gt 5\n",
      "pred 4 gt 4\n",
      "pred 5 gt 2\n",
      "pred 1 gt 0\n",
      "pred 1 gt 5\n",
      "pred 3 gt 0\n",
      "pred 6 gt 5\n",
      "pred 4 gt 1\n",
      "pred 5 gt 6\n",
      "pred 0 gt 5\n",
      "pred 1 gt 5\n",
      "pred 2 gt 3\n",
      "pred 4 gt 0\n",
      "pred 4 gt 6\n",
      "pred 2 gt 5\n",
      "pred 5 gt 4\n",
      "pred 4 gt 5\n",
      "pred 4 gt 0\n",
      "pred 1 gt 6\n",
      "pred 1 gt 2\n",
      "pred 4 gt 1\n",
      "pred 1 gt 5\n",
      "pred 4 gt 1\n",
      "pred 4 gt 2\n",
      "pred 2 gt 0\n",
      "pred 4 gt 4\n",
      "pred 4 gt 3\n",
      "pred 0 gt 1\n",
      "pred 2 gt 6\n",
      "pred 6 gt 6\n",
      "19/20 [===========================>..] - ETA: 4s - loss: -1.2983 - accuracy: 0.1406WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 4 gt 3\n",
      "pred 4 gt 5\n",
      "pred 1 gt 1\n",
      "pred 4 gt 6\n",
      "pred 1 gt 5\n",
      "pred 2 gt 0\n",
      "pred 3 gt 2\n",
      "pred 4 gt 4\n",
      "pred 4 gt 0\n",
      "pred 4 gt 3\n",
      "pred 4 gt 6\n",
      "pred 1 gt 2\n",
      "pred 1 gt 1\n",
      "pred 2 gt 0\n",
      "pred 0 gt 6\n",
      "pred 1 gt 0\n",
      "pred 4 gt 5\n",
      "pred 0 gt 6\n",
      "pred 4 gt 1\n",
      "pred 6 gt 3\n",
      "pred 3 gt 6\n",
      "pred 1 gt 6\n",
      "pred 4 gt 0\n",
      "pred 6 gt 0\n",
      "pred 0 gt 5\n",
      "pred 1 gt 5\n",
      "pred 4 gt 6\n",
      "pred 6 gt 0\n",
      "pred 1 gt 3\n",
      "pred 1 gt 0\n",
      "pred 1 gt 5\n",
      "pred 1 gt 2\n",
      "pred 1 gt 4\n",
      "pred 5 gt 6\n",
      "pred 1 gt 4\n",
      "pred 4 gt 4\n",
      "pred 4 gt 2\n",
      "pred 4 gt 1\n",
      "pred 1 gt 5\n",
      "pred 3 gt 4\n",
      "pred 0 gt 0\n",
      "pred 6 gt 5\n",
      "pred 4 gt 1\n",
      "pred 4 gt 1\n",
      "pred 3 gt 6\n",
      "pred 1 gt 3\n",
      "pred 2 gt 0\n",
      "pred 4 gt 3\n",
      "pred 2 gt 5\n",
      "pred 1 gt 3\n",
      "pred 5 gt 6\n",
      "pred 3 gt 6\n",
      "pred 2 gt 1\n",
      "pred 2 gt 6\n",
      "pred 2 gt 5\n",
      "pred 6 gt 3\n",
      "pred 1 gt 5\n",
      "pred 1 gt 3\n",
      "pred 3 gt 0\n",
      "pred 4 gt 5\n",
      "pred 1 gt 6\n",
      "pred 1 gt 5\n",
      "pred 4 gt 4\n",
      "20/20 [==============================] - ETA: 0s - loss: -1.3319 - accuracy: 0.1383pred 4 gt 3\n",
      "pred 4 gt 0\n",
      "pred 4 gt 3\n",
      "pred 4 gt 2\n",
      "pred 4 gt 6\n",
      "pred 4 gt 2\n",
      "pred 4 gt 2\n",
      "pred 4 gt 2\n",
      "pred 4 gt 3\n",
      "pred 4 gt 0\n",
      "pred 4 gt 6\n",
      "pred 4 gt 6\n",
      "pred 4 gt 6\n",
      "pred 4 gt 6\n",
      "pred 4 gt 6\n",
      "pred 4 gt 2\n",
      "pred 4 gt 4\n",
      "pred 4 gt 6\n",
      "pred 4 gt 6\n",
      "pred 4 gt 3\n",
      "pred 4 gt 5\n",
      "pred 4 gt 1\n",
      "pred 4 gt 2\n",
      "pred 4 gt 0\n",
      "pred 4 gt 5\n",
      "pred 4 gt 5\n",
      "pred 4 gt 0\n",
      "pred 4 gt 3\n",
      "pred 4 gt 2\n",
      "pred 4 gt 1\n",
      "pred 4 gt 1\n",
      "pred 4 gt 5\n",
      "pred 4 gt 4\n",
      "pred 4 gt 5\n",
      "pred 4 gt 4\n",
      "pred 4 gt 5\n",
      "pred 4 gt 0\n",
      "pred 4 gt 1\n",
      "pred 4 gt 3\n",
      "pred 4 gt 3\n",
      "pred 4 gt 0\n",
      "pred 4 gt 4\n",
      "pred 4 gt 3\n",
      "pred 4 gt 2\n",
      "pred 4 gt 4\n",
      "pred 4 gt 2\n",
      "pred 4 gt 6\n",
      "pred 4 gt 1\n",
      "pred 4 gt 0\n",
      "pred 4 gt 2\n",
      "pred 4 gt 6\n",
      "pred 4 gt 3\n",
      "pred 4 gt 6\n",
      "pred 4 gt 0\n",
      "pred 4 gt 2\n",
      "pred 4 gt 1\n",
      "pred 4 gt 1\n",
      "pred 4 gt 0\n",
      "pred 4 gt 3\n",
      "pred 4 gt 0\n",
      "pred 4 gt 2\n",
      "pred 4 gt 1\n",
      "pred 4 gt 3\n",
      "pred 4 gt 5\n",
      "pred 4 gt 3\n",
      "pred 4 gt 1\n",
      "pred 4 gt 5\n",
      "pred 4 gt 3\n",
      "pred 4 gt 0\n",
      "pred 4 gt 1\n",
      "pred 4 gt 4\n",
      "pred 4 gt 0\n",
      "pred 4 gt 1\n",
      "pred 4 gt 2\n",
      "pred 4 gt 6\n",
      "pred 4 gt 1\n",
      "pred 4 gt 0\n",
      "pred 4 gt 3\n",
      "pred 4 gt 4\n",
      "pred 4 gt 0\n",
      "pred 4 gt 6\n",
      "pred 4 gt 4\n",
      "pred 4 gt 2\n",
      "pred 4 gt 5\n",
      "pred 4 gt 0\n",
      "pred 4 gt 4\n",
      "pred 4 gt 4\n",
      "pred 4 gt 1\n",
      "pred 4 gt 3\n",
      "pred 4 gt 0\n",
      "pred 4 gt 1\n",
      "pred 4 gt 6\n",
      "pred 4 gt 1\n",
      "pred 4 gt 3\n",
      "pred 4 gt 2\n",
      "pred 4 gt 6\n",
      "pred 4 gt 6\n",
      "pred 4 gt 1\n",
      "pred 4 gt 1\n",
      "pred 4 gt 5\n",
      "pred 4 gt 4\n",
      "pred 4 gt 5\n",
      "pred 4 gt 5\n",
      "pred 4 gt 1\n",
      "pred 4 gt 4\n",
      "pred 4 gt 4\n",
      "pred 4 gt 4\n",
      "pred 4 gt 5\n",
      "pred 4 gt 5\n",
      "pred 4 gt 2\n",
      "pred 4 gt 6\n",
      "pred 4 gt 2\n",
      "pred 4 gt 6\n",
      "pred 4 gt 2\n",
      "pred 4 gt 4\n",
      "pred 4 gt 1\n",
      "pred 4 gt 1\n",
      "pred 4 gt 4\n",
      "pred 4 gt 5\n",
      "pred 4 gt 3\n",
      "pred 4 gt 3\n",
      "pred 4 gt 4\n",
      "pred 4 gt 6\n",
      "pred 4 gt 0\n",
      "pred 4 gt 6\n",
      "pred 4 gt 5\n",
      "pred 4 gt 0\n",
      "pred 4 gt 4\n",
      "pred 4 gt 5\n",
      "pred 4 gt 0\n",
      "pred 4 gt 2\n",
      "pred 4 gt 3\n",
      "pred 4 gt 2\n",
      "pred 4 gt 0\n",
      "pred 4 gt 5\n",
      "pred 4 gt 5\n",
      "pred 4 gt 4\n",
      "20/20 [==============================] - 105s 5s/step - loss: -1.3319 - accuracy: 0.1383 - val_loss: -1.1515 - val_accuracy: 0.0990\n",
      "Epoch 2/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 0 gt 1\n",
      "pred 1 gt 3\n",
      "pred 6 gt 4\n",
      "pred 5 gt 5\n",
      "pred 1 gt 4\n",
      "pred 3 gt 4\n",
      "pred 6 gt 0\n",
      "pred 5 gt 1\n",
      "pred 1 gt 6\n",
      "pred 3 gt 0\n",
      "pred 6 gt 4\n",
      "pred 2 gt 3\n",
      "pred 0 gt 2\n",
      "pred 4 gt 2\n",
      "pred 6 gt 1\n",
      "pred 2 gt 6\n",
      "pred 4 gt 3\n",
      "pred 1 gt 4\n",
      "pred 4 gt 1\n",
      "pred 1 gt 1\n",
      "pred 2 gt 0\n",
      "pred 6 gt 0\n",
      "pred 3 gt 2\n",
      "pred 5 gt 0\n",
      "pred 2 gt 5\n",
      "pred 6 gt 4\n",
      "pred 1 gt 0\n",
      "pred 5 gt 5\n",
      "pred 4 gt 2\n",
      "pred 5 gt 1\n",
      "pred 1 gt 0\n",
      "pred 4 gt 1\n",
      "pred 5 gt 1\n",
      "pred 1 gt 0\n",
      "pred 4 gt 3\n",
      "pred 5 gt 4\n",
      "pred 4 gt 5\n",
      "pred 1 gt 1\n",
      "pred 4 gt 5\n",
      "pred 2 gt 0\n",
      "pred 2 gt 1\n",
      "pred 5 gt 0\n",
      "pred 3 gt 1\n",
      "pred 0 gt 5\n",
      "pred 4 gt 3\n",
      "pred 5 gt 6\n",
      "pred 3 gt 4\n",
      "pred 0 gt 2\n",
      "pred 0 gt 2\n",
      "pred 1 gt 6\n",
      "pred 4 gt 6\n",
      "pred 4 gt 0\n",
      "pred 4 gt 0\n",
      "pred 4 gt 3\n",
      "pred 1 gt 5\n",
      "pred 0 gt 1\n",
      "pred 0 gt 2\n",
      "pred 0 gt 3\n",
      "pred 5 gt 5\n",
      "pred 6 gt 5\n",
      "pred 3 gt 0\n",
      "pred 1 gt 5\n",
      "pred 4 gt 1\n",
      " 1/20 [>.............................] - ETA: 1:27 - loss: -1.5916 - accuracy: 0.0781WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 3 gt 2\n",
      "pred 1 gt 3\n",
      "pred 0 gt 0\n",
      "pred 5 gt 4\n",
      "pred 4 gt 6\n",
      "pred 1 gt 1\n",
      "pred 4 gt 0\n",
      "pred 3 gt 4\n",
      "pred 3 gt 1\n",
      "pred 2 gt 4\n",
      "pred 3 gt 3\n",
      "pred 3 gt 6\n",
      "pred 5 gt 0\n",
      "pred 2 gt 4\n",
      "pred 4 gt 4\n",
      "pred 1 gt 2\n",
      "pred 0 gt 1\n",
      "pred 0 gt 5\n",
      "pred 4 gt 4\n",
      "pred 6 gt 5\n",
      "pred 3 gt 2\n",
      "pred 1 gt 0\n",
      "pred 5 gt 2\n",
      "pred 4 gt 5\n",
      "pred 6 gt 4\n",
      "pred 4 gt 2\n",
      "pred 2 gt 2\n",
      "pred 4 gt 1\n",
      "pred 1 gt 0\n",
      "pred 4 gt 1\n",
      "pred 0 gt 1\n",
      "pred 5 gt 1\n",
      "pred 1 gt 3\n",
      "pred 6 gt 5\n",
      "pred 0 gt 6\n",
      "pred 3 gt 3\n",
      "pred 4 gt 1\n",
      "pred 1 gt 2\n",
      "pred 4 gt 2\n",
      "pred 2 gt 2\n",
      "pred 1 gt 1\n",
      "pred 0 gt 4\n",
      "pred 5 gt 0\n",
      "pred 4 gt 5\n",
      "pred 6 gt 0\n",
      "pred 4 gt 4\n",
      "pred 1 gt 1\n",
      "pred 6 gt 5\n",
      "pred 5 gt 4\n",
      "pred 0 gt 5\n",
      "pred 1 gt 5\n",
      "pred 0 gt 1\n",
      "pred 1 gt 6\n",
      "pred 5 gt 6\n",
      "pred 1 gt 5\n",
      "pred 4 gt 4\n",
      "pred 1 gt 4\n",
      "pred 1 gt 6\n",
      "pred 1 gt 3\n",
      "pred 6 gt 1\n",
      "pred 1 gt 5\n",
      "pred 6 gt 5\n",
      "pred 2 gt 0\n",
      " 2/20 [==>...........................] - ETA: 1:26 - loss: -1.5734 - accuracy: 0.1328WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 0 gt 0\n",
      "pred 3 gt 0\n",
      "pred 4 gt 2\n",
      "pred 2 gt 6\n",
      "pred 2 gt 4\n",
      "pred 6 gt 2\n",
      "pred 1 gt 0\n",
      "pred 6 gt 3\n",
      "pred 4 gt 0\n",
      "pred 4 gt 1\n",
      "pred 3 gt 1\n",
      "pred 5 gt 5\n",
      "pred 1 gt 4\n",
      "pred 1 gt 0\n",
      "pred 0 gt 4\n",
      "pred 0 gt 0\n",
      "pred 1 gt 5\n",
      "pred 6 gt 0\n",
      "pred 1 gt 1\n",
      "pred 4 gt 4\n",
      "pred 2 gt 0\n",
      "pred 6 gt 0\n",
      "pred 0 gt 5\n",
      "pred 4 gt 3\n",
      "pred 0 gt 0\n",
      "pred 5 gt 0\n",
      "pred 0 gt 5\n",
      "pred 1 gt 4\n",
      "pred 2 gt 0\n",
      "pred 1 gt 5\n",
      "pred 6 gt 1\n",
      "pred 0 gt 5\n",
      "pred 6 gt 5\n",
      "pred 5 gt 3\n",
      "pred 2 gt 3\n",
      "pred 1 gt 1\n",
      "pred 1 gt 4\n",
      "pred 1 gt 5\n",
      "pred 0 gt 1\n",
      "pred 2 gt 3\n",
      "pred 4 gt 1\n",
      "pred 4 gt 1\n",
      "pred 4 gt 4\n",
      "pred 4 gt 6\n",
      "pred 6 gt 1\n",
      "pred 1 gt 4\n",
      "pred 4 gt 4\n",
      "pred 5 gt 6\n",
      "pred 2 gt 4\n",
      "pred 4 gt 1\n",
      "pred 1 gt 2\n",
      "pred 1 gt 0\n",
      "pred 6 gt 3\n",
      "pred 5 gt 3\n",
      "pred 1 gt 4\n",
      "pred 4 gt 6\n",
      "pred 1 gt 0\n",
      "pred 1 gt 6\n",
      "pred 4 gt 0\n",
      "pred 0 gt 0\n",
      "pred 4 gt 6\n",
      "pred 1 gt 1\n",
      "pred 3 gt 6\n",
      " 3/20 [===>..........................] - ETA: 1:23 - loss: -1.6114 - accuracy: 0.1458WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 4 gt 6\n",
      "pred 3 gt 5\n",
      "pred 3 gt 6\n",
      "pred 3 gt 3\n",
      "pred 4 gt 1\n",
      "pred 2 gt 6\n",
      "pred 4 gt 6\n",
      "pred 6 gt 0\n",
      "pred 1 gt 4\n",
      "pred 0 gt 6\n",
      "pred 6 gt 2\n",
      "pred 5 gt 6\n",
      "pred 1 gt 4\n",
      "pred 4 gt 1\n",
      "pred 4 gt 4\n",
      "pred 4 gt 5\n",
      "pred 2 gt 0\n",
      "pred 0 gt 1\n",
      "pred 1 gt 6\n",
      "pred 0 gt 4\n",
      "pred 4 gt 4\n",
      "pred 2 gt 3\n",
      "pred 4 gt 0\n",
      "pred 2 gt 5\n",
      "pred 6 gt 5\n",
      "pred 3 gt 6\n",
      "pred 2 gt 4\n",
      "pred 5 gt 4\n",
      "pred 4 gt 2\n",
      "pred 4 gt 6\n",
      "pred 3 gt 1\n",
      "pred 4 gt 2\n",
      "pred 2 gt 6\n",
      "pred 2 gt 6\n",
      "pred 4 gt 0\n",
      "pred 2 gt 2\n",
      "pred 4 gt 5\n",
      "pred 3 gt 3\n",
      "pred 5 gt 2\n",
      "pred 5 gt 2\n",
      "pred 4 gt 0\n",
      "pred 1 gt 1\n",
      "pred 5 gt 1\n",
      "pred 4 gt 4\n",
      "pred 4 gt 2\n",
      "pred 6 gt 3\n",
      "pred 1 gt 6\n",
      "pred 5 gt 2\n",
      "pred 4 gt 2\n",
      "pred 1 gt 3\n",
      "pred 4 gt 1\n",
      "pred 5 gt 6\n",
      "pred 5 gt 2\n",
      "pred 5 gt 0\n",
      "pred 4 gt 2\n",
      "pred 1 gt 0\n",
      "pred 5 gt 4\n",
      "pred 1 gt 2\n",
      "pred 2 gt 6\n",
      "pred 6 gt 5\n",
      "pred 6 gt 2\n",
      "pred 0 gt 3\n",
      "pred 4 gt 5\n",
      " 4/20 [=====>........................] - ETA: 1:18 - loss: -1.3334 - accuracy: 0.1367WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 0 gt 3\n",
      "pred 4 gt 2\n",
      "pred 4 gt 4\n",
      "pred 0 gt 0\n",
      "pred 6 gt 1\n",
      "pred 5 gt 2\n",
      "pred 4 gt 2\n",
      "pred 2 gt 0\n",
      "pred 0 gt 2\n",
      "pred 5 gt 0\n",
      "pred 6 gt 0\n",
      "pred 4 gt 3\n",
      "pred 5 gt 3\n",
      "pred 5 gt 1\n",
      "pred 4 gt 1\n",
      "pred 4 gt 2\n",
      "pred 5 gt 2\n",
      "pred 0 gt 5\n",
      "pred 2 gt 5\n",
      "pred 6 gt 2\n",
      "pred 5 gt 1\n",
      "pred 3 gt 4\n",
      "pred 6 gt 5\n",
      "pred 1 gt 6\n",
      "pred 4 gt 0\n",
      "pred 3 gt 4\n",
      "pred 1 gt 6\n",
      "pred 1 gt 4\n",
      "pred 4 gt 1\n",
      "pred 0 gt 4\n",
      "pred 5 gt 6\n",
      "pred 1 gt 4\n",
      "pred 4 gt 6\n",
      "pred 4 gt 5\n",
      "pred 0 gt 2\n",
      "pred 4 gt 6\n",
      "pred 0 gt 5\n",
      "pred 3 gt 2\n",
      "pred 1 gt 2\n",
      "pred 4 gt 2\n",
      "pred 4 gt 1\n",
      "pred 3 gt 6\n",
      "pred 4 gt 0\n",
      "pred 1 gt 6\n",
      "pred 6 gt 0\n",
      "pred 1 gt 1\n",
      "pred 4 gt 3\n",
      "pred 4 gt 2\n",
      "pred 3 gt 2\n",
      "pred 5 gt 6\n",
      "pred 4 gt 6\n",
      "pred 1 gt 5\n",
      "pred 0 gt 5\n",
      "pred 2 gt 3\n",
      "pred 1 gt 6\n",
      "pred 1 gt 2\n",
      "pred 5 gt 6\n",
      "pred 2 gt 1\n",
      "pred 1 gt 5\n",
      "pred 1 gt 0\n",
      "pred 2 gt 0\n",
      "pred 4 gt 5\n",
      "pred 4 gt 2\n",
      " 5/20 [======>.......................] - ETA: 1:13 - loss: -1.1901 - accuracy: 0.1187WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 6 gt 1\n",
      "pred 6 gt 0\n",
      "pred 5 gt 1\n",
      "pred 1 gt 5\n",
      "pred 5 gt 6\n",
      "pred 6 gt 0\n",
      "pred 6 gt 4\n",
      "pred 5 gt 5\n",
      "pred 4 gt 3\n",
      "pred 3 gt 3\n",
      "pred 1 gt 1\n",
      "pred 1 gt 3\n",
      "pred 4 gt 1\n",
      "pred 5 gt 3\n",
      "pred 4 gt 3\n",
      "pred 2 gt 2\n",
      "pred 5 gt 0\n",
      "pred 1 gt 3\n",
      "pred 5 gt 4\n",
      "pred 2 gt 2\n",
      "pred 6 gt 0\n",
      "pred 4 gt 0\n",
      "pred 1 gt 2\n",
      "pred 4 gt 6\n",
      "pred 5 gt 1\n",
      "pred 4 gt 2\n",
      "pred 2 gt 0\n",
      "pred 5 gt 3\n",
      "pred 4 gt 6\n",
      "pred 1 gt 6\n",
      "pred 1 gt 2\n",
      "pred 5 gt 0\n",
      "pred 6 gt 0\n",
      "pred 2 gt 1\n",
      "pred 4 gt 1\n",
      "pred 4 gt 3\n",
      "pred 0 gt 5\n",
      "pred 2 gt 2\n",
      "pred 4 gt 4\n",
      "pred 2 gt 1\n",
      "pred 4 gt 3\n",
      "pred 4 gt 4\n",
      "pred 4 gt 6\n",
      "pred 4 gt 0\n",
      "pred 4 gt 1\n",
      "pred 1 gt 1\n",
      "pred 4 gt 5\n",
      "pred 4 gt 0\n",
      "pred 1 gt 5\n",
      "pred 2 gt 3\n",
      "pred 1 gt 3\n",
      "pred 1 gt 1\n",
      "pred 1 gt 3\n",
      "pred 4 gt 3\n",
      "pred 4 gt 2\n",
      "pred 4 gt 0\n",
      "pred 1 gt 4\n",
      "pred 2 gt 1\n",
      "pred 4 gt 0\n",
      "pred 1 gt 3\n",
      "pred 2 gt 6\n",
      "pred 1 gt 1\n",
      "pred 2 gt 1\n",
      " 6/20 [========>.....................] - ETA: 1:08 - loss: -1.2488 - accuracy: 0.1276WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 0 gt 5\n",
      "pred 2 gt 0\n",
      "pred 2 gt 1\n",
      "pred 4 gt 1\n",
      "pred 3 gt 4\n",
      "pred 5 gt 2\n",
      "pred 5 gt 2\n",
      "pred 6 gt 6\n",
      "pred 1 gt 3\n",
      "pred 1 gt 4\n",
      "pred 5 gt 3\n",
      "pred 4 gt 6\n",
      "pred 1 gt 3\n",
      "pred 2 gt 0\n",
      "pred 4 gt 5\n",
      "pred 2 gt 5\n",
      "pred 0 gt 6\n",
      "pred 0 gt 4\n",
      "pred 4 gt 0\n",
      "pred 5 gt 4\n",
      "pred 4 gt 4\n",
      "pred 3 gt 1\n",
      "pred 2 gt 5\n",
      "pred 2 gt 6\n",
      "pred 4 gt 3\n",
      "pred 2 gt 6\n",
      "pred 4 gt 0\n",
      "pred 2 gt 3\n",
      "pred 2 gt 6\n",
      "pred 5 gt 0\n",
      "pred 1 gt 2\n",
      "pred 0 gt 6\n",
      "pred 6 gt 0\n",
      "pred 1 gt 4\n",
      "pred 6 gt 6\n",
      "pred 1 gt 2\n",
      "pred 1 gt 6\n",
      "pred 3 gt 4\n",
      "pred 4 gt 3\n",
      "pred 4 gt 1\n",
      "pred 3 gt 6\n",
      "pred 4 gt 4\n",
      "pred 3 gt 4\n",
      "pred 1 gt 2\n",
      "pred 4 gt 6\n",
      "pred 2 gt 0\n",
      "pred 4 gt 6\n",
      "pred 4 gt 0\n",
      "pred 6 gt 4\n",
      "pred 1 gt 3\n",
      "pred 2 gt 3\n",
      "pred 3 gt 1\n",
      "pred 1 gt 3\n",
      "pred 0 gt 5\n",
      "pred 1 gt 2\n",
      "pred 0 gt 0\n",
      "pred 0 gt 4\n",
      "pred 4 gt 2\n",
      "pred 4 gt 0\n",
      "pred 0 gt 3\n",
      "pred 5 gt 1\n",
      "pred 3 gt 4\n",
      "pred 2 gt 5\n",
      " 7/20 [=========>....................] - ETA: 1:03 - loss: -1.2255 - accuracy: 0.1205WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 1 gt 0\n",
      "pred 6 gt 4\n",
      "pred 6 gt 4\n",
      "pred 4 gt 1\n",
      "pred 3 gt 1\n",
      "pred 4 gt 6\n",
      "pred 0 gt 1\n",
      "pred 5 gt 0\n",
      "pred 1 gt 5\n",
      "pred 0 gt 5\n",
      "pred 5 gt 3\n",
      "pred 3 gt 3\n",
      "pred 1 gt 3\n",
      "pred 4 gt 3\n",
      "pred 2 gt 5\n",
      "pred 4 gt 2\n",
      "pred 6 gt 2\n",
      "pred 2 gt 6\n",
      "pred 0 gt 5\n",
      "pred 2 gt 5\n",
      "pred 3 gt 2\n",
      "pred 4 gt 5\n",
      "pred 0 gt 0\n",
      "pred 0 gt 2\n",
      "pred 2 gt 1\n",
      "pred 1 gt 1\n",
      "pred 4 gt 0\n",
      "pred 3 gt 2\n",
      "pred 3 gt 3\n",
      "pred 5 gt 5\n",
      "pred 1 gt 1\n",
      "pred 2 gt 6\n",
      "pred 1 gt 2\n",
      "pred 3 gt 4\n",
      "pred 5 gt 3\n",
      "pred 4 gt 6\n",
      "pred 4 gt 1\n",
      "pred 1 gt 6\n",
      "pred 2 gt 6\n",
      "pred 4 gt 6\n",
      "pred 4 gt 2\n",
      "pred 1 gt 1\n",
      "pred 3 gt 2\n",
      "pred 6 gt 0\n",
      "pred 3 gt 4\n",
      "pred 4 gt 6\n",
      "pred 5 gt 4\n",
      "pred 1 gt 6\n",
      "pred 1 gt 6\n",
      "pred 6 gt 3\n",
      "pred 4 gt 2\n",
      "pred 2 gt 1\n",
      "pred 0 gt 2\n",
      "pred 4 gt 0\n",
      "pred 3 gt 4\n",
      "pred 6 gt 2\n",
      "pred 4 gt 6\n",
      "pred 2 gt 6\n",
      "pred 4 gt 5\n",
      "pred 4 gt 4\n",
      "pred 5 gt 2\n",
      "pred 0 gt 3\n",
      "pred 1 gt 1\n",
      " 8/20 [===========>..................] - ETA: 59s - loss: -1.1940 - accuracy: 0.1230 WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 3 gt 4\n",
      "pred 5 gt 3\n",
      "pred 4 gt 2\n",
      "pred 6 gt 6\n",
      "pred 3 gt 4\n",
      "pred 1 gt 3\n",
      "pred 3 gt 5\n",
      "pred 0 gt 3\n",
      "pred 2 gt 5\n",
      "pred 4 gt 5\n",
      "pred 2 gt 2\n",
      "pred 0 gt 6\n",
      "pred 1 gt 5\n",
      "pred 2 gt 5\n",
      "pred 1 gt 5\n",
      "pred 1 gt 4\n",
      "pred 4 gt 5\n",
      "pred 0 gt 5\n",
      "pred 4 gt 3\n",
      "pred 3 gt 0\n",
      "pred 6 gt 0\n",
      "pred 1 gt 0\n",
      "pred 2 gt 3\n",
      "pred 0 gt 6\n",
      "pred 1 gt 6\n",
      "pred 4 gt 1\n",
      "pred 2 gt 5\n",
      "pred 3 gt 5\n",
      "pred 5 gt 6\n",
      "pred 5 gt 0\n",
      "pred 2 gt 0\n",
      "pred 4 gt 3\n",
      "pred 1 gt 0\n",
      "pred 4 gt 3\n",
      "pred 4 gt 6\n",
      "pred 4 gt 0\n",
      "pred 4 gt 4\n",
      "pred 2 gt 2\n",
      "pred 4 gt 2\n",
      "pred 5 gt 6\n",
      "pred 4 gt 5\n",
      "pred 4 gt 2\n",
      "pred 1 gt 0\n",
      "pred 6 gt 0\n",
      "pred 2 gt 4\n",
      "pred 2 gt 1\n",
      "pred 4 gt 3\n",
      "pred 4 gt 6\n",
      "pred 2 gt 0\n",
      "pred 2 gt 0\n",
      "pred 6 gt 0\n",
      "pred 1 gt 3\n",
      "pred 2 gt 1\n",
      "pred 4 gt 4\n",
      "pred 1 gt 4\n",
      "pred 4 gt 2\n",
      "pred 6 gt 0\n",
      "pred 0 gt 4\n",
      "pred 2 gt 6\n",
      "pred 1 gt 2\n",
      "pred 4 gt 0\n",
      "pred 2 gt 6\n",
      "pred 4 gt 2\n",
      " 9/20 [============>.................] - ETA: 54s - loss: -1.2074 - accuracy: 0.1181WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 1 gt 5\n",
      "pred 2 gt 1\n",
      "pred 6 gt 2\n",
      "pred 2 gt 0\n",
      "pred 4 gt 3\n",
      "pred 1 gt 6\n",
      "pred 2 gt 3\n",
      "pred 3 gt 1\n",
      "pred 3 gt 5\n",
      "pred 1 gt 3\n",
      "pred 3 gt 3\n",
      "pred 4 gt 6\n",
      "pred 0 gt 5\n",
      "pred 0 gt 6\n",
      "pred 4 gt 6\n",
      "pred 1 gt 1\n",
      "pred 1 gt 4\n",
      "pred 4 gt 0\n",
      "pred 0 gt 6\n",
      "pred 4 gt 1\n",
      "pred 0 gt 5\n",
      "pred 6 gt 2\n",
      "pred 1 gt 5\n",
      "pred 6 gt 4\n",
      "pred 3 gt 1\n",
      "pred 4 gt 2\n",
      "pred 0 gt 1\n",
      "pred 1 gt 2\n",
      "pred 4 gt 4\n",
      "pred 1 gt 6\n",
      "pred 1 gt 1\n",
      "pred 6 gt 2\n",
      "pred 3 gt 6\n",
      "pred 0 gt 0\n",
      "pred 3 gt 1\n",
      "pred 1 gt 3\n",
      "pred 1 gt 4\n",
      "pred 1 gt 5\n",
      "pred 0 gt 5\n",
      "pred 4 gt 5\n",
      "pred 2 gt 1\n",
      "pred 1 gt 6\n",
      "pred 0 gt 1\n",
      "10/20 [==============>...............] - ETA: 46s - loss: -1.2137 - accuracy: 0.1141WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 1 gt 0\n",
      "pred 0 gt 5\n",
      "pred 4 gt 2\n",
      "pred 0 gt 1\n",
      "pred 4 gt 4\n",
      "pred 3 gt 4\n",
      "pred 2 gt 2\n",
      "pred 4 gt 3\n",
      "pred 6 gt 4\n",
      "pred 4 gt 1\n",
      "pred 2 gt 5\n",
      "pred 5 gt 2\n",
      "pred 5 gt 1\n",
      "pred 4 gt 1\n",
      "pred 3 gt 0\n",
      "pred 3 gt 2\n",
      "pred 3 gt 0\n",
      "pred 4 gt 2\n",
      "pred 2 gt 1\n",
      "pred 2 gt 0\n",
      "pred 0 gt 3\n",
      "pred 5 gt 6\n",
      "pred 2 gt 3\n",
      "pred 4 gt 2\n",
      "pred 1 gt 4\n",
      "pred 3 gt 3\n",
      "pred 4 gt 3\n",
      "pred 5 gt 3\n",
      "pred 4 gt 2\n",
      "pred 5 gt 0\n",
      "pred 4 gt 0\n",
      "pred 0 gt 0\n",
      "pred 4 gt 6\n",
      "pred 3 gt 2\n",
      "pred 6 gt 5\n",
      "pred 2 gt 1\n",
      "pred 4 gt 3\n",
      "pred 5 gt 1\n",
      "pred 0 gt 5\n",
      "pred 4 gt 1\n",
      "pred 4 gt 4\n",
      "pred 2 gt 4\n",
      "pred 4 gt 2\n",
      "pred 4 gt 3\n",
      "pred 2 gt 2\n",
      "pred 3 gt 3\n",
      "pred 2 gt 1\n",
      "pred 1 gt 4\n",
      "pred 0 gt 5\n",
      "pred 5 gt 1\n",
      "pred 6 gt 0\n",
      "pred 6 gt 6\n",
      "pred 6 gt 1\n",
      "pred 0 gt 4\n",
      "pred 0 gt 4\n",
      "pred 2 gt 6\n",
      "pred 3 gt 3\n",
      "pred 1 gt 1\n",
      "pred 4 gt 6\n",
      "pred 6 gt 5\n",
      "pred 3 gt 1\n",
      "pred 4 gt 0\n",
      "pred 1 gt 3\n",
      "11/20 [===============>..............] - ETA: 42s - loss: -1.2184 - accuracy: 0.1179WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 1 gt 1\n",
      "pred 2 gt 1\n",
      "pred 2 gt 4\n",
      "pred 1 gt 6\n",
      "pred 2 gt 2\n",
      "pred 0 gt 0\n",
      "pred 3 gt 2\n",
      "pred 0 gt 6\n",
      "pred 2 gt 3\n",
      "pred 6 gt 6\n",
      "pred 1 gt 2\n",
      "pred 5 gt 2\n",
      "pred 0 gt 5\n",
      "pred 4 gt 5\n",
      "pred 4 gt 2\n",
      "pred 1 gt 6\n",
      "pred 4 gt 3\n",
      "pred 0 gt 4\n",
      "pred 4 gt 2\n",
      "pred 6 gt 5\n",
      "pred 0 gt 6\n",
      "pred 1 gt 6\n",
      "pred 3 gt 1\n",
      "pred 3 gt 1\n",
      "pred 6 gt 4\n",
      "pred 4 gt 2\n",
      "pred 4 gt 4\n",
      "pred 2 gt 3\n",
      "pred 4 gt 2\n",
      "pred 1 gt 4\n",
      "pred 5 gt 1\n",
      "pred 6 gt 3\n",
      "pred 3 gt 4\n",
      "pred 4 gt 5\n",
      "pred 4 gt 2\n",
      "pred 6 gt 1\n",
      "pred 1 gt 0\n",
      "pred 5 gt 3\n",
      "pred 2 gt 1\n",
      "pred 6 gt 4\n",
      "pred 5 gt 6\n",
      "pred 4 gt 3\n",
      "pred 5 gt 5\n",
      "pred 2 gt 1\n",
      "pred 4 gt 3\n",
      "pred 2 gt 4\n",
      "pred 2 gt 1\n",
      "pred 1 gt 0\n",
      "pred 5 gt 6\n",
      "pred 3 gt 2\n",
      "pred 4 gt 1\n",
      "pred 6 gt 5\n",
      "pred 5 gt 1\n",
      "pred 6 gt 3\n",
      "pred 3 gt 6\n",
      "pred 4 gt 1\n",
      "pred 4 gt 1\n",
      "pred 1 gt 5\n",
      "pred 2 gt 0\n",
      "pred 2 gt 6\n",
      "pred 2 gt 2\n",
      "pred 3 gt 0\n",
      "pred 4 gt 5\n",
      "12/20 [=================>............] - ETA: 37s - loss: -1.2170 - accuracy: 0.1172WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 2 gt 0\n",
      "pred 3 gt 3\n",
      "pred 3 gt 5\n",
      "pred 2 gt 1\n",
      "pred 4 gt 1\n",
      "pred 4 gt 2\n",
      "pred 4 gt 4\n",
      "pred 6 gt 5\n",
      "pred 3 gt 2\n",
      "pred 2 gt 2\n",
      "pred 2 gt 3\n",
      "pred 1 gt 3\n",
      "pred 3 gt 2\n",
      "pred 4 gt 3\n",
      "pred 4 gt 1\n",
      "pred 4 gt 4\n",
      "pred 4 gt 3\n",
      "pred 2 gt 5\n",
      "pred 3 gt 4\n",
      "pred 2 gt 0\n",
      "pred 0 gt 3\n",
      "pred 4 gt 3\n",
      "pred 2 gt 4\n",
      "pred 2 gt 1\n",
      "pred 1 gt 3\n",
      "pred 1 gt 3\n",
      "pred 1 gt 3\n",
      "pred 6 gt 1\n",
      "pred 5 gt 1\n",
      "pred 5 gt 6\n",
      "pred 1 gt 5\n",
      "pred 1 gt 6\n",
      "pred 5 gt 2\n",
      "pred 2 gt 6\n",
      "pred 0 gt 6\n",
      "pred 1 gt 2\n",
      "pred 4 gt 3\n",
      "pred 1 gt 5\n",
      "pred 4 gt 5\n",
      "pred 3 gt 4\n",
      "pred 5 gt 0\n",
      "pred 1 gt 0\n",
      "pred 6 gt 4\n",
      "pred 6 gt 6\n",
      "pred 2 gt 0\n",
      "pred 3 gt 5\n",
      "pred 0 gt 3\n",
      "pred 1 gt 5\n",
      "pred 4 gt 5\n",
      "pred 3 gt 0\n",
      "pred 4 gt 3\n",
      "pred 3 gt 3\n",
      "pred 1 gt 0\n",
      "pred 1 gt 3\n",
      "pred 1 gt 4\n",
      "pred 5 gt 2\n",
      "pred 2 gt 2\n",
      "pred 4 gt 0\n",
      "pred 6 gt 6\n",
      "pred 4 gt 2\n",
      "pred 2 gt 5\n",
      "pred 2 gt 5\n",
      "pred 4 gt 6\n",
      "13/20 [==================>...........] - ETA: 32s - loss: -1.2568 - accuracy: 0.1178WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 6 gt 3\n",
      "pred 5 gt 0\n",
      "pred 0 gt 2\n",
      "pred 1 gt 6\n",
      "pred 2 gt 0\n",
      "pred 5 gt 6\n",
      "pred 4 gt 0\n",
      "pred 1 gt 2\n",
      "pred 5 gt 0\n",
      "pred 0 gt 1\n",
      "pred 1 gt 4\n",
      "pred 4 gt 2\n",
      "pred 2 gt 6\n",
      "pred 2 gt 6\n",
      "pred 2 gt 6\n",
      "pred 4 gt 3\n",
      "pred 6 gt 1\n",
      "pred 4 gt 5\n",
      "pred 2 gt 3\n",
      "pred 4 gt 0\n",
      "pred 0 gt 3\n",
      "pred 4 gt 5\n",
      "pred 1 gt 3\n",
      "pred 0 gt 0\n",
      "pred 4 gt 4\n",
      "pred 6 gt 3\n",
      "pred 2 gt 0\n",
      "pred 0 gt 4\n",
      "pred 2 gt 5\n",
      "pred 2 gt 2\n",
      "pred 4 gt 2\n",
      "pred 3 gt 2\n",
      "pred 1 gt 5\n",
      "pred 5 gt 5\n",
      "pred 1 gt 3\n",
      "pred 1 gt 5\n",
      "pred 2 gt 4\n",
      "pred 1 gt 5\n",
      "pred 5 gt 0\n",
      "pred 5 gt 5\n",
      "pred 6 gt 4\n",
      "pred 4 gt 1\n",
      "pred 4 gt 4\n",
      "pred 3 gt 3\n",
      "pred 3 gt 6\n",
      "pred 2 gt 5\n",
      "pred 3 gt 3\n",
      "pred 4 gt 2\n",
      "pred 2 gt 6\n",
      "pred 2 gt 2\n",
      "pred 2 gt 4\n",
      "pred 4 gt 3\n",
      "pred 0 gt 2\n",
      "pred 1 gt 6\n",
      "pred 4 gt 3\n",
      "pred 4 gt 6\n",
      "pred 4 gt 4\n",
      "pred 6 gt 1\n",
      "pred 2 gt 4\n",
      "pred 6 gt 0\n",
      "pred 2 gt 1\n",
      "pred 2 gt 6\n",
      "pred 2 gt 2\n",
      "14/20 [====================>.........] - ETA: 28s - loss: -1.2576 - accuracy: 0.1217WARNING:tensorflow:Gradients do not exist for variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'conv2d_3/bias:0', 'batch_normalization_2/gamma:0', 'batch_normalization_2/beta:0', 'conv2d_4/bias:0', 'batch_normalization_3/gamma:0', 'batch_normalization_3/beta:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "pred 1 gt 5\n",
      "pred 2 gt 1\n",
      "pred 3 gt 3\n",
      "pred 2 gt 5\n",
      "pred 4 gt 5\n",
      "pred 1 gt 5\n",
      "pred 2 gt 1\n",
      "pred 1 gt 3\n",
      "pred 2 gt 6\n",
      "pred 0 gt 3\n",
      "pred 1 gt 2\n",
      "pred 4 gt 4\n",
      "pred 1 gt 1\n",
      "pred 3 gt 4\n",
      "pred 6 gt 6\n",
      "pred 0 gt 2\n",
      "pred 6 gt 5\n",
      "pred 3 gt 5\n",
      "pred 5 gt 1\n",
      "pred 2 gt 0\n",
      "pred 4 gt 1\n",
      "pred 4 gt 5\n",
      "pred 6 gt 2\n",
      "pred 4 gt 0\n",
      "pred 3 gt 4\n",
      "pred 4 gt 4\n",
      "pred 4 gt 5\n",
      "pred 4 gt 6\n",
      "pred 4 gt 3\n",
      "pred 1 gt 0\n",
      "pred 4 gt 2\n",
      "pred 6 gt 4\n",
      "pred 0 gt 3\n",
      "pred 4 gt 1\n",
      "pred 5 gt 6\n",
      "pred 4 gt 4\n",
      "pred 5 gt 5\n",
      "pred 0 gt 2\n",
      "pred 3 gt 3\n",
      "pred 1 gt 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13648/1075653153.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    876\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m         \u001b[1;34m\"\"\"Runs a training execution with one step.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 878\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstep_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m       \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 867\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m       outputs = reduce_per_replica(\n\u001b[0;32m    869\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1314\u001b[0m       fn = autograph.tf_convert(\n\u001b[0;32m   1315\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m-> 1316\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2890\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2891\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2892\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2894\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3693\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3694\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3695\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3697\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    599\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mrun_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m         \u001b[1;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    815\u001b[0m     \u001b[1;31m# Run backwards pass.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 817\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    818\u001b[0m     \u001b[1;31m# Collect metrics to return\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m     \u001b[0mreturn_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\compile_utils.py\u001b[0m in \u001b[0;36mupdate_state\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m    458\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmetric_obj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m           \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m         \u001b[0mmetric_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mweighted_metric_obj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mweighted_metric_objs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\metrics_utils.py\u001b[0m in \u001b[0;36mdecorated\u001b[1;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_context_for_symbolic_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m       \u001b[0mupdate_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_state_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mupdate_op\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# update_op will be None in eager execution.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m       \u001b[0mmetric_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\metrics.py\u001b[0m in \u001b[0;36mupdate_state_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mcontrol_status\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mag_update_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_update_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontrol_status\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mag_update_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFunction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    694\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    335\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Allowlisted %s: from cache'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    465\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\metrics.py\u001b[0m in \u001b[0;36mupdate_state\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m     \u001b[0mag_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 725\u001b[1;33m     \u001b[0mmatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    726\u001b[0m     return super(MeanMetricWrapper, self).update_state(\n\u001b[0;32m    727\u001b[0m         matches, sample_weight=sample_weight)\n",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    694\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    443\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filel1way1qc.py\u001b[0m in \u001b[0;36mtf__accuracy\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m                 \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m                 \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m                 \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop_body_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_state_3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_state_3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'iterate_names'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'n'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py\u001b[0m in \u001b[0;36mfor_stmt\u001b[1;34m(iter_, extra_test, body, get_state, set_state, symbol_names, opts)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m     \u001b[0m_py_for_stmt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py\u001b[0m in \u001b[0;36m_py_for_stmt\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    491\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miter_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m       \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py\u001b[0m in \u001b[0;36mprotected_body\u001b[1;34m(protected_iter)\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[0moriginal_body\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprotected_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprotected_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m       \u001b[0moriginal_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprotected_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    460\u001b[0m       \u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m       \u001b[0mbefore_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filel1way1qc.py\u001b[0m in \u001b[0;36mloop_body_1\u001b[1;34m(itr_1)\u001b[0m\n\u001b[0;32m     20\u001b[0m                     \u001b[1;32mnonlocal\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitr_1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                     \u001b[0my_pred_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m                     \u001b[0my_true_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filel1way1qc.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     20\u001b[0m                     \u001b[1;32mnonlocal\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitr_1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                     \u001b[0my_pred_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m                     \u001b[0my_true_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    335\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Allowlisted %s: from cache'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    463\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1148\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1150\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(x = train_generator, epochs = epochs, validation_data = validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig , ax = plt.subplots(1,2)\n",
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "fig.set_size_inches(12,4)\n",
    "\n",
    "ax[0].plot(history.history['accuracy'])\n",
    "ax[0].plot(history.history['val_accuracy'])\n",
    "ax[0].set_title('Training accuracy vs Validation accuracy')\n",
    "ax[0].set_ylabel('accuracy')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "ax[1].plot(history.history['loss'])\n",
    "ax[1].plot(history.history['val_loss'])\n",
    "ax[1].set_title('Training Loss vs Validation Loss')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_optimal.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc = model.evaluate(train_generator)\n",
    "test_loss, test_acc   = model.evaluate(validation_generator)\n",
    "print(\"final train recall = {:.2f} , validation recall = {:.2f} , train_loss = {:.2f} , validation_loss = {:.2f}\".format(train_acc*100, test_acc*100, train_loss, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# t-SNE   \n",
    "def plot_vecs_n_labels(v, labels, fname):\n",
    "    fig = plt.figure(figsize = (10,10))\n",
    "    plt.axis('off')\n",
    "    sns.set_style('darkgrid')\n",
    "    sns.scatterplot(v[:,0], hue=labels, legend='full', palette=sns.color_palette(\"bright\", 10))\n",
    "    plt.legend(['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise'])\n",
    "    plt.savefig(fname)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "val_dl = validation_generator\n",
    "\n",
    "for x, y in val_dl:\n",
    "    #x = x.to(device)\n",
    "    pred = model.predict(x)\n",
    "    w = -100 \n",
    "    for m in range(len(weight)) :\n",
    "        a = cosine_similarity(weight[m], pred[1])\n",
    "        if w < a : \n",
    "            w = a\n",
    "            i = m\n",
    "    pred = [[i]]\n",
    "        #pred = linear_classifier(pred)\n",
    "        \n",
    "    #   tsne.fit_transform \n",
    "    pred_tsne = tsne.fit_transform(x.reshape(-1, 1), pred)\n",
    "    \n",
    "    # t-SNE   \n",
    "    plot_vecs_n_labels(pred_tsne, y, 'tsen.png')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a926afa313b26ae1264fdcf81c726a97e69f6ba2ba780f6aa901948710f8d6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
